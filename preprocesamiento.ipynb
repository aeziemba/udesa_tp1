{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTAMOS LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\alejandra.ziemba\\anaconda3\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\alejandra.ziemba\\anaconda3\\lib\\site-packages (from geopy) (2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\alejandra.ziemba\\anaconda3\\lib\\site-packages (1.6.2)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\alejandra.ziemba\\anaconda3\\lib\\site-packages (from scipy) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install geopy\n",
    "!pip install scipy \n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import scipy.stats\n",
    "import seaborn as sbs\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de muestra: 16585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TAXI\n",
    "#armamos una funcion para calcular el tamaño de muestra\n",
    "#asumiendo una distribucion normal\n",
    "def sample_size(population_size, margin_of_error, confidence_level, sigma):\n",
    "    z = norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "    n_0 = (z ** 2 * sigma ** 2) / (margin_of_error ** 2)\n",
    "    n = n_0 / (1 + ((n_0 - 1) / population_size))\n",
    "    return int(round(n))\n",
    "\n",
    "#parametros \n",
    "population_size_taxi = 139000000\n",
    "margin_of_error = 0.01\n",
    "confidence_level = 0.99\n",
    "#no conocemos el desvio estandard, por lo que asumimos maxima variabilidad, lo que implica un sigma de 0.5\n",
    "sigma = 0.5\n",
    "\n",
    "#pasamos parametros como argumentos a la funcion e imprimimos el tamaño de muestra\n",
    "n_taxi = sample_size(population_size_taxi, margin_of_error, confidence_level, sigma)\n",
    "print(f'Tamaño de muestra: {n_taxi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16587.241958099352"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comprobamos asumiendo un distribucion t de student con los mismo parametros el tamaño de la muestra\n",
    "t_alpha_2=scipy.stats.t.ppf(1-0.01/2, df=population_size_taxi-1)\n",
    "s=0.5\n",
    "E=0.01\n",
    "ty = (((t_alpha_2)**2)*(s**2))\n",
    "n_taxi2=ty/(E**2)\n",
    "n_taxi2\n",
    "#la funcion devuelve una dimension muy similar para el dataset de taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de muestra: 16567\n"
     ]
    }
   ],
   "source": [
    "population_size_bici = 13800000\n",
    "\n",
    "#pasamos parametros como argumentos a la funcion e imprimimos el tamaño de muestra\n",
    "n_bici = sample_size(population_size_bici, margin_of_error, confidence_level, sigma)\n",
    "print(f'Tamaño de muestra: {n_bici}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16587.246091027966"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comprobamos asumiendo un distribucion t de student con los mismo parametros el tamaño de la muestra\n",
    "t_alpha_2=scipy.stats.t.ppf(1-0.01/2, df=population_size_bici-1)\n",
    "s=0.5\n",
    "E=0.01\n",
    "ty = (((t_alpha_2)**2)*(s**2))\n",
    "n_bici2=ty/(E**2)\n",
    "n_bici2\n",
    "#la funcion devuelve una dimension muy similar para el dataset de taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#el porcentaje de la muestra deseada es el tamaño de muestra dividido la poblacion\n",
    "#n/139000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011931654676258992"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#muestra en relacion a la poblacion de taxi\n",
    "muestra_per_taxi=(n_taxi/population_size_taxi)\n",
    "muestra_per_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012005072463768115"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#muestra en relacion a la poblacion de bici\n",
    "muestra_per_bici=(n_bici/population_size_bici)\n",
    "muestra_per_bici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREAMOS UN DATAFRAME CONSOLIDADO CON LOS ARCHIVOS DESCARGADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'yellow_tripdata_2016-01.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6814e679d2f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#lectura del archivo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdf_aux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'yellow_tripdata_2016-{i:02d}.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m#muestra aleatoria del 1%, con una semilla para reproducibilidad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdf_aux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_aux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmuestra_per_taxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \"\"\"\n\u001b[0;32m    458\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m     return impl.read(\n\u001b[0m\u001b[0;32m    460\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m                 )\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"filesystem\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m# fsspec resources can also point to directories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mhandles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mpath_or_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yellow_tripdata_2016-01.parquet'"
     ]
    }
   ],
   "source": [
    "#TAXI\n",
    "#creamos dataframe vacio\n",
    "df_taxi=pd.DataFrame()\n",
    "#bucle para cada 1 de los 12 archivos descargados, donde solo varia el mes en el nombre\n",
    "for i in range(1,13):\n",
    "    #lectura del archivo\n",
    "    df_aux = pd.read_parquet(f'yellow_tripdata_2016-{i:02d}.parquet')\n",
    "    #muestra aleatoria del 1%, con una semilla para reproducibilidad\n",
    "    df_aux = df_aux.sample(frac=muestra_per_taxi, random_state=4)\n",
    "    #concatenamos o adjuntamos el archivo muestreado en el consolidado\n",
    "    df_taxi = pd.concat([df_taxi, df_aux]).reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCEDEMOS A AGREGAR ALGUNAS COLUMNAS EN LOS DOS DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BICI\n",
    "#creamos dataframe vacio\n",
    "df_bici=pd.DataFrame()\n",
    "#bucle para cada 1 de los 12 archivos descargados, donde solo varia el mes en el nombre\n",
    "for i in range(1,13):\n",
    "    #lectura del archivo\n",
    "    df_aux = pd.read_csv(f'Bicis/2016{i:02d}-citibike-tripdata.csv')\n",
    "    #muestra aleatoria del 1%, con una semilla para reproducibilidad\n",
    "    df_aux = df_aux.sample(frac=muestra_per_bici, random_state=4)\n",
    "    df_aux.columns=df_aux.columns.str.lower()\n",
    "        # verificar si la columna 'startime' está presente en df_aux\n",
    "    if 'starttime' in df_aux.columns:\n",
    "        df_aux = df_aux.rename(columns={'starttime': 'start time'})\n",
    "    if 'stoptime' in df_aux.columns:\n",
    "        df_aux = df_aux.rename(columns={'stoptime': 'stop time'})\n",
    "    if 'tripduration' in df_aux.columns:\n",
    "        df_aux = df_aux.rename(columns={'tripduration': 'trip duration'})\n",
    "    if 'bikeid' in df_aux.columns:\n",
    "        df_aux = df_aux.rename(columns={'bikeid': 'bike id'})\n",
    "    if 'usertype' in df_aux.columns:\n",
    "        df_aux = df_aux.rename(columns={'usertype': 'user type'})\n",
    "    #concatenamos o adjuntamos el archivo muestreado en el consolidado\n",
    "    df_bici = pd.concat([df_bici, df_aux]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bici=pd.read_csv('Bicis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot describe a DataFrame without columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-de5b1a413722>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_taxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdescribe\u001b[1;34m(self, percentiles, include, exclude, datetime_is_numeric)\u001b[0m\n\u001b[0;32m  10273\u001b[0m         \"\"\"\n\u001b[0;32m  10274\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10275\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot describe a DataFrame without columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpercentiles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot describe a DataFrame without columns"
     ]
    }
   ],
   "source": [
    "df_taxi.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAXI\n",
    "#agregamos algunas columnas utiles: duracion del viaje en minutos, dias de semana y el mes.\n",
    "\n",
    "# Convierte las columnas de fecha y hora en objetos de fecha y hora de Pandas.\n",
    "df_taxi['tpep_pickup_datetime'] = pd.to_datetime(df_taxi['tpep_pickup_datetime'])\n",
    "df_taxi['tpep_dropoff_datetime'] = pd.to_datetime(df_taxi['tpep_dropoff_datetime'])\n",
    "\n",
    "# Crea una nueva columna de duración de viaje en minutos\n",
    "df_taxi['trip_duration_mins'] = (df_taxi['tpep_dropoff_datetime'] - df_taxi['tpep_pickup_datetime']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dias de semana\n",
    "df_taxi['week_day']=df_taxi['tpep_pickup_datetime'].dt.dayofweek\n",
    "day_names = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "df_taxi['week_day']=df_taxi['week_day'].map(day_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mes del año\n",
    "df_taxi['month'] = pd.DatetimeIndex(df_taxi['tpep_pickup_datetime']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BICI\n",
    "# Agregamos una columna con el día de la semana que se corresponde con el viaje\n",
    "df_bici['stop time']=pd.to_datetime(df_bici['stop time'])\n",
    "df_bici['week_day']=df_bici['stop time'].dt.dayofweek\n",
    "day_names = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "df_bici['week_day'] = df_bici['week_day'].map(day_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bici['month'] = pd.DatetimeIndex(df_bici['stop time']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos una columna con las distancias recorridas en cada viaje\n",
    "\n",
    "# Definir una función para calcular la distancia entre dos puntos\n",
    "df_bici_copy=df_bici.copy()\n",
    "\n",
    "def distancia_entre_puntos(row):\n",
    "    coords_1 = (row['start station latitude'], row['start station longitude'])\n",
    "    coords_2 = (row['end station latitude'], row['end station longitude'])\n",
    "    return geopy.distance.distance(coords_1, coords_2).miles\n",
    "\n",
    "# Aplicar la función a cada fila del dataframe y calcular la distancia recorrida en cada viaje\n",
    "df_bici_copy.loc[:,'distancia (ml)'] = df_bici_copy.apply(distancia_entre_puntos, axis=1)\n",
    "df_bici=df_bici_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duracion del viaje en minutos\n",
    "df_bici['trip duration mins']=df_bici['trip duration']/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trip duration</th>\n",
       "      <th>start time</th>\n",
       "      <th>stop time</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bike id</th>\n",
       "      <th>user type</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "      <th>week_day</th>\n",
       "      <th>month</th>\n",
       "      <th>distancia (ml)</th>\n",
       "      <th>trip duration mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16615</th>\n",
       "      <td>16615</td>\n",
       "      <td>1279</td>\n",
       "      <td>2016-12-12 17:18:33</td>\n",
       "      <td>2016-12-12 17:39:53</td>\n",
       "      <td>383</td>\n",
       "      <td>Greenwich Ave &amp; Charles St</td>\n",
       "      <td>40.735238</td>\n",
       "      <td>-74.000271</td>\n",
       "      <td>523</td>\n",
       "      <td>W 38 St &amp; 8 Ave</td>\n",
       "      <td>40.754666</td>\n",
       "      <td>-73.991382</td>\n",
       "      <td>20528</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>12</td>\n",
       "      <td>1.419433</td>\n",
       "      <td>21.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16616</th>\n",
       "      <td>16616</td>\n",
       "      <td>1725</td>\n",
       "      <td>2016-12-30 19:38:45</td>\n",
       "      <td>2016-12-30 20:07:31</td>\n",
       "      <td>147</td>\n",
       "      <td>Greenwich St &amp; Warren St</td>\n",
       "      <td>40.715422</td>\n",
       "      <td>-74.011220</td>\n",
       "      <td>488</td>\n",
       "      <td>W 39 St &amp; 9 Ave</td>\n",
       "      <td>40.756458</td>\n",
       "      <td>-73.993722</td>\n",
       "      <td>22301</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>12</td>\n",
       "      <td>2.976819</td>\n",
       "      <td>28.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16617</th>\n",
       "      <td>16617</td>\n",
       "      <td>937</td>\n",
       "      <td>2016-12-21 09:31:19</td>\n",
       "      <td>2016-12-21 09:46:57</td>\n",
       "      <td>498</td>\n",
       "      <td>Broadway &amp; W 32 St</td>\n",
       "      <td>40.748549</td>\n",
       "      <td>-73.988084</td>\n",
       "      <td>151</td>\n",
       "      <td>Cleveland Pl &amp; Spring St</td>\n",
       "      <td>40.722104</td>\n",
       "      <td>-73.997249</td>\n",
       "      <td>17979</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>12</td>\n",
       "      <td>1.887101</td>\n",
       "      <td>15.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16618</th>\n",
       "      <td>16618</td>\n",
       "      <td>412</td>\n",
       "      <td>2016-12-11 16:13:01</td>\n",
       "      <td>2016-12-11 16:19:53</td>\n",
       "      <td>248</td>\n",
       "      <td>Laight St &amp; Hudson St</td>\n",
       "      <td>40.721854</td>\n",
       "      <td>-74.007718</td>\n",
       "      <td>368</td>\n",
       "      <td>Carmine St &amp; 6 Ave</td>\n",
       "      <td>40.730386</td>\n",
       "      <td>-74.002150</td>\n",
       "      <td>19105</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>12</td>\n",
       "      <td>0.657305</td>\n",
       "      <td>6.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16619</th>\n",
       "      <td>16619</td>\n",
       "      <td>1267</td>\n",
       "      <td>2016-12-28 04:23:37</td>\n",
       "      <td>2016-12-28 04:44:44</td>\n",
       "      <td>3263</td>\n",
       "      <td>Cooper Square &amp; E 7 St</td>\n",
       "      <td>40.729236</td>\n",
       "      <td>-73.990868</td>\n",
       "      <td>380</td>\n",
       "      <td>W 4 St &amp; 7 Ave S</td>\n",
       "      <td>40.734011</td>\n",
       "      <td>-74.002939</td>\n",
       "      <td>26395</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>12</td>\n",
       "      <td>0.714149</td>\n",
       "      <td>21.116667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  trip duration           start time           stop time  \\\n",
       "16615       16615           1279  2016-12-12 17:18:33 2016-12-12 17:39:53   \n",
       "16616       16616           1725  2016-12-30 19:38:45 2016-12-30 20:07:31   \n",
       "16617       16617            937  2016-12-21 09:31:19 2016-12-21 09:46:57   \n",
       "16618       16618            412  2016-12-11 16:13:01 2016-12-11 16:19:53   \n",
       "16619       16619           1267  2016-12-28 04:23:37 2016-12-28 04:44:44   \n",
       "\n",
       "       start station id          start station name  start station latitude  \\\n",
       "16615               383  Greenwich Ave & Charles St               40.735238   \n",
       "16616               147    Greenwich St & Warren St               40.715422   \n",
       "16617               498          Broadway & W 32 St               40.748549   \n",
       "16618               248       Laight St & Hudson St               40.721854   \n",
       "16619              3263      Cooper Square & E 7 St               40.729236   \n",
       "\n",
       "       start station longitude  end station id          end station name  \\\n",
       "16615               -74.000271             523           W 38 St & 8 Ave   \n",
       "16616               -74.011220             488           W 39 St & 9 Ave   \n",
       "16617               -73.988084             151  Cleveland Pl & Spring St   \n",
       "16618               -74.007718             368        Carmine St & 6 Ave   \n",
       "16619               -73.990868             380          W 4 St & 7 Ave S   \n",
       "\n",
       "       end station latitude  end station longitude  bike id   user type  \\\n",
       "16615             40.754666             -73.991382    20528  Subscriber   \n",
       "16616             40.756458             -73.993722    22301  Subscriber   \n",
       "16617             40.722104             -73.997249    17979  Subscriber   \n",
       "16618             40.730386             -74.002150    19105  Subscriber   \n",
       "16619             40.734011             -74.002939    26395    Customer   \n",
       "\n",
       "       birth year  gender   week_day  month  distancia (ml)  \\\n",
       "16615      1964.0       2     Monday     12        1.419433   \n",
       "16616      1969.0       1     Friday     12        2.976819   \n",
       "16617      1982.0       2  Wednesday     12        1.887101   \n",
       "16618      1978.0       1     Sunday     12        0.657305   \n",
       "16619         NaN       0  Wednesday     12        0.714149   \n",
       "\n",
       "       trip duration mins  \n",
       "16615           21.316667  \n",
       "16616           28.750000  \n",
       "16617           15.616667  \n",
       "16618            6.866667  \n",
       "16619           21.116667  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bici.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos la limpieza del dataset, en este caso tratando de identificar si hay valores negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#TAXI\n",
    "#comenzamos por los nulls\n",
    "columns_with_nulls = df_taxi.columns[df_taxi.isnull().any()].tolist()\n",
    "print(columns_with_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#la totalidad de los valores de las dos columnas con nulos, por lo que no vamos a usar las columnas y no consideramos relevante eliminarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot describe a DataFrame without columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-de5b1a413722>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_taxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdescribe\u001b[1;34m(self, percentiles, include, exclude, datetime_is_numeric)\u001b[0m\n\u001b[0;32m  10273\u001b[0m         \"\"\"\n\u001b[0;32m  10274\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10275\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot describe a DataFrame without columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpercentiles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot describe a DataFrame without columns"
     ]
    }
   ],
   "source": [
    "df_taxi.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consultamos viajes con cero pasajeros\n",
    "pasajeros_cero=df_taxi.query('passenger_count==0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos una lista con los indices de las filas con cero pasajeros\n",
    "index_list1 = pasajeros_cero.index.tolist()\n",
    "#eliminamos esas filas de df_taxi\n",
    "df_taxi = df_taxi.drop(index_list1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consultamos viajes distancia de viaje 0\n",
    "distancia_cero=df_taxi.query('trip_distance==0')\n",
    "#creamos una lista con los indices de las filas con distancia cero.\n",
    "index_list1 = distancia_cero.index.tolist()\n",
    "#eliminamos esas filas de df_taxi\n",
    "df_taxi = df_taxi.drop(index_list1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionamos solo columnas de tipo numerico\n",
    "numeric_cols = df_taxi.select_dtypes(include=['number'])\n",
    "# seleccionamos solo filas con algun valor negativo.\n",
    "neg_rows = df_taxi[numeric_cols.lt(0).any(axis=1)]\n",
    "neg_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos una lista con los indices de las filas con valores negativas\n",
    "index_list = neg_rows.index.tolist()\n",
    "#eliminamos esas filas de df_taxi\n",
    "df_taxi = df_taxi.drop(index_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BICI\n",
    "#chequeamos viajes con distancia en 0 \n",
    "df_bici_d0=df_bici.loc[df_bici['distancia (ml)'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos las filas del dataset, ya que distorsionan el analisis\n",
    "df_bici = df_bici.drop(df_bici[df_bici['distancia (ml)'] == 0].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELIMINAMOS FILAS CON VALORES 0 EN COORDENADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar las filas con valores nulos y/o con valores reales 0.0 en las columnas \"start station latitude\", \"start station longitude\", \"end station latitude\" y \"end station longitude\"\n",
    "df_bici = df_bici.loc[(df_bici['start station latitude'] != 0.0) & \n",
    "                      (df_bici['start station longitude'] != 0.0) & \n",
    "                      (df_bici['end station latitude'] != 0.0) & \n",
    "                      (df_bici['end station longitude'] != 0.0) & \n",
    "                      (~df_bici['start station latitude'].isnull()) & \n",
    "                      (~df_bici['start station longitude'].isnull()) & \n",
    "                      (~df_bici['end station latitude'].isnull()) & \n",
    "                      (~df_bici['end station longitude'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Hay\n"
     ]
    }
   ],
   "source": [
    "#Taxi\n",
    "#chequamos si hay duplicados\n",
    "hay_duplicados = df_taxi.duplicated().any()\n",
    "\n",
    "if hay_duplicados:\n",
    "    print ( \"Hay\")\n",
    "else:\n",
    "    print (\"No Hay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Hay\n"
     ]
    }
   ],
   "source": [
    "#Bici\n",
    "#chequamos si hay duplicados\n",
    "hay_duplicados = df_bici.duplicated().any()\n",
    "\n",
    "if hay_duplicados:\n",
    "    print ( \"Hay\")\n",
    "else:\n",
    "    print (\"No Hay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trip duration</th>\n",
       "      <th>start time</th>\n",
       "      <th>stop time</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bike id</th>\n",
       "      <th>user type</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "      <th>week_day</th>\n",
       "      <th>month</th>\n",
       "      <th>distancia (ml)</th>\n",
       "      <th>trip duration mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, trip duration, start time, stop time, start station id, start station name, start station latitude, start station longitude, end station id, end station name, end station latitude, end station longitude, bike id, user type, birth year, gender, week_day, month, distancia (ml), trip duration mins]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bici\n",
    "# seleccionamos solo columnas de tipo numerico\n",
    "numeric_cols = df_bici.select_dtypes(include=['number'])\n",
    "sd=numeric_cols.drop(['start station longitude','end station longitude'],axis=1)\n",
    "# seleccionamos solo filas con algun valor negativo.\n",
    "neg_rows = df_bici[sd.lt(0).any(axis=1)]\n",
    "neg_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
